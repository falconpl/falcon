/*
   FALCON - Generic Parser

   FILE: parser.fal

   Generic parser (using Falcon Grammar)
   -------------------------------------------------------------------
   Author: Giancarlo Niccolai
   Begin: Wed, 02 Jul 2014 14:37:04 +0200

   -------------------------------------------------------------------
   (C) Copyright 2014: the FALCON developers (see list in AUTHORS file)

   See LICENSE file for licensing details.
*/

import Grammar from .grammar

/*#
   @module genparser
   @brief Generic parser
   
   This module provides funcitonality to parse a given input using an abstract
   grammar structure.
   
   The grammar structure being used to parse the text is provided by the
   @a parser.grammar module and @a parser.stdgrammars module, which helps to load in
   some well-known grammars.
*/

// Associativity constants
_anone = 0
_aleft = 1
_aright = 2

/* Basic Earley item */
class _EarleyItem(prod, orig, dot)
   prod = prod
   dot = dot ? dot : 0   
   orig = orig
   
   //# True if incomplete
   function incomplete()
      return self.dot < self.prod.sequence.len
   end
   
   //# Return the next DefEntry in the rule sequence.
   function nextDefEntry()
      seq = self.prod.sequence
      if self.dot >= seq.len: return nil
      return seq[self.dot]
   end
   
   function describe()
      pos = 0
      // ok even if nil
      dt = self.prod.symbol.name +  " => "
      
      seq = self.prod.sequence
      while pos < seq.len
         if pos > 0: dt += " "
         if pos == self.dot: dt += "(*)"
         dentry = seq[pos]
         dt += dentry.toString()
         ++pos
      end
      
      if self.dot == seq.len: dt += "(*)"
      
      dt += " @" + self.orig
      return dt
   end
   
   
   function compare(other)
      if other provides prod and other provides dot and other provides orig
         if self.prod > other.prod: return 1
         if self.prod < other.prod: return -1
         if self.dot != other.dot: return self.dot - other.dot
         return self.orig - other.orig
      end
      return nil
   end
   
   function equals(other)
      return self.prod == other.prod and self.dot == other.dot and self.orig == other.orig
   end
end


class _EarleyChart(id)
   id = id
   list = []
   
   function add(item)
      for i = 0 to self.list.len - 1,1
         c = self.list[i]
         // already added
         if item.equals(c)  
            return 
         end
      end
      
      self.list += item
   end
   
   function describe()
      rt = m"[\n"
      for item in self.list 
         rt += "      " + item.describe() + "\n"
      end
      rt += "     ]"
      return rt
   end
end


class _EarleyPlan(rootRule)
   charts = nil
   current = 0
   
   init
      l = _EarleyChart(0)
      l.list += _EarleyItem( rootRule, 0 )
      self.charts = [l]
   end
   
   function describe()
      ret = m"["
      ch = 0
      for chart in self.charts
         forfirst: ret += "\n"
         ret += "  " + (ch++) + ": " + chart.describe() + "\n"
      end
      ret +="]"
      return ret         
   end
   
end


/* Tau */
class _Tau(value, token)
   value = value
   token = token
   
   function describe()
      return self.token.name.toString() + ": >" + self.value.describe() + "<"
   end
end


/* Current working state */
class _CWS(state)
   state = state
   // stack of active charts
   plan = nil
   
   sequence = []
   
   init
      // We are sure that the top symbol is synthetized as having a rule.
      self.plan = _EarleyPlan(state.top.alts[0])
   end
end

/*#
   @brief Generic parser using an abstract grammar definition.
   
   The grammar used by this parser can be synthesized programmatically,
   or parsed from an EBNF-like definition. This functionality is provided
   by the @a parser.grammar module.

*/

class Parser(grammar)
   //# Error in running code
   static eCode = 1
   
   //# Error generated on unrecognized rule
   static eMatch = 2
   
   //# Stack unferflow in state popping
   static eUflow = 3
   
   //# Unrecognised sequence at eof
   static eUEOF = 4
   
   //# Grammar used by this parser
   grammar = grammar
   
   //# Topmost token recognized after a succesful parsing
   recon = nil
   
   //# Count of errors generated by the parsing
   errors = 0
   
   // Active token stack.
   _tokenStack = nil
   
   // Active state
   _curState = nil
   
   // Internally used eof   
   _eof = nil
   
   /*#
      @brief Error handler function
      
      This property is assinged a function that receives the
      notification of an error in the grammar. On error, 
      it is invoked with the following parameters:
         - The line where the error happened.
         - Numeric code of the error
         - A textual description of the error that happened.
         - Extensive contextual information.
         
      If the line is 0, then the error happened while processing the
      input grammar rather than while matching the input.

      The default function writes the error notification to the process
      standard output. It can be overridden to change its behavior.
   */
   handleError = function( parser, line, code, reason, extra )
         desc = parser.describeError(code)
         desc = @"[$line] $desc($code)"
         if reason: desc += "(" + reason + ")"
         if extra: desc += ": " + extra
         printl(desc)
      end
   
   
   // Multi-tokenizer used for lexing.
   _mt = nil
   
   // The state stack
   // -- List of _CWS (current working state)
   _states = nil
   
   // the context generated by the code.
   _ctx = nil

   init
      // a formal check on grammar
      if not grammar.derivedFrom(Grammar)
         raise ParamError(901,nil,"Grammar")
      end
      
      if "main" notin grammar.states
         raise ParamError(1001,"Invalid grammar","Provided grammar has no 'main' state.")
      end
      
      self.grammar = grammar
   end
   
   /*#
      @brief Parses an input stream according to the given grammar.
      @return On success, the value associated with the recognized token.
      @param idata Input data (a String or a TextReader)
      
   */
   function parse(idata)
      try
         mt = MultiTokenizer(idata)
         mt.countLines = true
         self._mt = mt
      catch ParamError 
         raise ParamError( 1001, "Invalid paramters", "Need a string or TextReader" )
      end

      self._reset()      

      ctx = self._runInitCode()
      if not ctx: ctx = p{}
      self._ctx = ctx
            
      // cache the grammar predefined eof
      self._eof = self.grammar.predefined["eof"]
      
      self._parseLoop()
         
      self.dump()
      return self.errors == 0
   end
   
   //============================================================
   // Parser workhorse -- unify current guess into rules
   //============================================================
   
   function _parseLoop()
         
      // do the preamble -- we have checked the grammar "main" at init
      main = self.grammar.states["main"]
      self._enter(main)
   
      loop
         cws = self._states[-1]
         seq = cws.sequence
         seq += self._getNextToken()
         self._trace( "States ", self._states.len, ", tokens ", seq.len )
         
         charts = cws.plan.charts
         current = seq.len-1
         chart = charts[current]
         // chart.len will change as the predictor adds new items
         itemNum = 0
         while itemNum < chart.list.len
            item = chart.list[itemNum]
            if item.incomplete()
               de = item.nextDefEntry()
               if de.symbol.isTerminal()
                  self._scanner( charts, current, item, seq[current] )
               else
                  self._predictor( chart, current, item )                  
               end
            else
               self._completer(charts, current, item)
            end
            
            ++itemNum
         end         
         
         > "=" * 50 + " Loop " + current
         > cws.plan.describe()
         Debugger.breakpoint()
      end seq[-1].token == self._eof
         
      > cws.plan.describe()
         
      // We want the top guess stack to be [TOP <eof>]
      // And we we find a top guess stack with [... <eof>] that's an error.      
      /*if guess.sequence.len == 1 and guess.sequence[0] == self._eof
         return true
      end
      
      // unrecognized stuff at end
      self.error( self.eUEOF )*/
      return false
   end
   
   function _predictor(chart, id, item )
      // we know de is non-terminal
      de = item.nextDefEntry()
      self._trace("Predicting new items for ", de.symbol.name )
      for r in de.symbol.alts
         itm = _EarleyItem( r, id )         
         self._trace("Adding new prediction ", itm )
         chart.add( itm )
      end
      
   end
   
   
   // charts is an array of _EarleyChart
   function _scanner(charts, id, item, tau)
      self._trace("Scanning for ", tau, " at ", id)
      // we know de IS Terminal
      de = item.nextDefEntry()
      ++id
      if tau.token == de.symbol
         
         if charts.len == id
            self._trace("Adding a new chart")
            charts += _EarleyChart(id)
         end                 
         
         itm = item.clone()
         itm.dot++
         self._trace( "Adding scanned item", itm)
         charts[id].add(itm)
      end
   end
   
   function _completer( charts, id, item )
      orig = item.orig
      symbol = item.prod.symbol
      for itm in charts[orig].list
         if charts.len == id
            self._trace("Adding a new chart")
            charts += _EarleyChart(id)
         end
         
         // copying the completed entity
         de = itm.nextDefEntry()
         if de and de.symbol == symbol
             // filter priority items.
            if item.prod.pcheck()
               // we can add it only if there isn't an intersecting completed arc of lower priority
               frame = itm.dot + itm.orig
               if self._filterPrec( charts[frame], item.prod.leftPrec, item.prod.leftAssoc )
                  self._trace("Ignoring this item because frame ", frame, " has completed priority: ", itm )
                  continue
               end
            end
            
            itm = itm.clone()
            itm.dot ++ 
            self._trace("Adding new completion ", itm )
            charts[id].add( itm )
         end
      end            
   end

   function _filterPrec( chart, prec, assoc )      
      for i = 0 to chart.list.len-1
         item = chart.list[i]
         
         if item.prod.leftPrec > 0
            if item.prod.leftPrec < prec or \
               (item.prod.leftPrec == prec and item.prod.leftAssoc <= assoc )
               return true
            end
         end
      end
      
      return false
   end
   
   // error step of the parser loop
   function _error()
      // todo
   end
   
   // Applies a rule, reducing the sequence as described by the rule
   // Sequence is an array of _Tau
   // Rule is a DefRule
   function _applyRule( sequence, rl )
      target = rl.symbol
      ruleLen = rl.sequence.len
      
      // prepare the params now...
      if rl.compiled
         params = []
         
         for pcount = 0 to min(sequence.len, ruleLen)-1, 1
            entry = rl.sequence[pcount]
            self._trace("ENTRY: ", entry)
            if entry.pname
               params += sequence[pcount].value
            end
         end
      end
      
      // simplify
      value = sequence.empty ? nil : sequence[0].value
      
      self._trace( "Symplifying " + ruleLen + " tokens to " + target.name )
      if rl.sequence.len
         sequence.remove(0,rl.sequence.len)
      end
      
      tau = _Tau(value, target)
      sequence.insert(0, tau)
      
      // ...if the value is calculated, change it.
      if rl.compiled         
         self._trace( "Calling code for reduction rule to "+ target.name +":", params )
         value = self._runCode("Reduction rule " + target.name, rl.compiled, params )
         if not ^$ value
            self._trace( "Applying new value", value )
            tau.value = value
         end
      end
      
   end
   
   //============================================================
   // Utilities
   //============================================================
   
   function _getNextToken()
      mt = self._mt
      
      eat = self._states[-1].state.eat
      while mt.hasNext
         tau = mt.next()   // will be either nil, a string or a _Tau
         // skip empty tokens.
         if not tau: continue
         // eat the ignored tokens.
         if tau.typeId == StringType and tau in eat
            continue
         end
         
         // we have the tau
         return tau
      end
      
      // once hit the end, continue to generate end tokens
      return _Tau(self._end)
   end
   
   function _sendEOF()
   end
   
   
   function dump()
      for cws in self._states
         > "IN STATE: ", cws.state.name
         
         guessCount = 1
         for guess in cws.guesses
            > "   ", "Guess ", guessCount
            
            for tok in guess.sequence
               > "   "*2, tok.describe()
            end
            
            > "   ", "=== END OF Guess ", guessCount
            ++guessCount
         end
         
         >  "=== END OF State ", cws.state.name
      end         
   end
   
   function describeError(code)
      switch code
         case 1: return "Error in running code"
         case 2: return "Unrecognized grammar"
         case 3: return "Underflow in state pop"
         default: return ""
      end
   end
   
   function _reset()
      self._mt.giveTokens = true
      self._states = []      
   end
   
   // Enters a given GrammarState
   function _enter(state)
      
      if self._states
         oldState = self.states[-1].state
         self._runCode("Postamble of " + oldState.name, oldState.postamble_compiled )
      end
         
      self._runCode("Preamble of " + state.name, state.preamble_compiled )
      
      entry = _CWS(state)
      self._states.push(entry)      
      self._applyState(entry)
      
      return entry
   end
   
   
   // Leaves a given count of GrammarStates
   // if not given, cound defaults to 1
   function _leave(count)
      if not count: count = 1
      
      if self._states.len < 1 + count
         self.error( self.eUflow )
         return
      end
      
      while count > 0 
         oldState = self._states[-1].state
         self._runCode("Postamble of " + oldState.name, oldState.postamble_compiled )
         
         self._states.pop()
         cws = self._states[-1]
         self._runCode("Preamble of " + cws.state.name, cws.state.preamble_compiled )
         --count
      end
      
      self._applyState(cws)            
   end

   
   function _applyState(cws)
   
      state = cws.state
      mt = self._mt
      mt.clearTokens()
      for value, entry in state.terminals
         //> "Value: >", value.describe(), "< => ", entry.describe()         
         
         // esclude "eat" terminals from well-formed terminals.
         if value in state.eat: continue
         
         // On a valid token, return a TAU of the actual token and parser entry.
         mt.addToken( value, {(t) ^= _Tau(t, ^~entry) })
      end
      
      // on generic text, yield an unnamed tau.
      mt.onText = {(t) ^= (t ? _Tau(t, nil) : nil) }
      
      if state.eat: call( self._mt.add, state.eat )
           
      self._curState = state
      
   end
   
   
   function _runInitCode()
      code = self.grammar.initcode_compiled
      if code
         try
            ctx = code()
         catch in e
            self.error( self.eCode, "Initcode", e.toString() )
         end
      end
   end
   
   function _runCode( context, code, params )
      if code
         if params
            params.insert(0,self._ctx)
         else
            params = [self._ctx]
         end
         
         try 
            return call( code, params )
         catch in e
            self.error( self.eCode, @"Application code in \"$context\"", e.toString() )
            return ^+ nil
         end
      end
   end
   
   
   function error( code, reason, extra )
      self.errors++
      self.handleError( self, self._mt.line, code, reason, extra )
   end
      
   function _trace(text)
      >> "[", Function.caller, "] "
      
      >> text
      for item in passvp()
         forfirst : >> " "
         >> item.describe()
         formiddle: >> ", "
      end
      >
   end
end
